hydra:
  output_subdir: null  # disable creating .hydra directory
  run:
    dir: .  # disable output directory created by hydra
  job:
    chdir: false  # disable changing working directory

usr_config: null  # e.g. project_root/configs/user_configs/user_config1.yaml

################### Don't modify parameters above #######################

################### You can modify all parameters below #################
defaults:
  - _self_  # import default.yaml itself
  - datasets: shapenet.yaml  # import shapenet.yaml
  - override hydra/hydra_logging: disabled   # disable hydra logging because we will use wandb as our logger
  - override hydra/job_logging: disabled   # disable job logging because we will use wandb as our logger

wandb:
  enable: true
  api_key: null  # your wandb api key
  project: null  # the name of your project
  entity: null  # the place to save your runs. can be your wandb username or team name
  name: ${now:%Y%m%d_%H%M%S}  # the name your run

train:
  epochs: 200
  lr: 1e-3
  lr_scheduler:
    enable: true
    which: stepLR  # expLR, stepLR or cosLR
    expLR:
      gamma: 0.95
    stepLR:
      gamma: 0.2  # lr = gamma * lr, when decay step is hit
      decay_step: 50
    cosLR:
      T_max: ${epochs}  # maximum epochs
      eta_min: 1e-3  # minimum lr
  optimizer: adam  # adam or sgd
  which_gpu: [0]  # if you want to use multiple gpus, enter [0, 1, 2] for gpu #0, #1, #2
  pin_memory: true  # pin memory in RAM
  validation_freq: 1  # frequency in epoch(s) to validate the model
  dataloader:
    batch_size: 8
    shuffle: true
    num_workers: 16  # the number of subprocess to load data
    prefetch: 32  # samples to be prefetched. e.g. 64 means 64*num_workers samples to be prefetched
    label_smoothing: true
    epsilon: 0.2

test:
  which_gpu: [0]  # the name of the run you want to test
  pin_memory: true  # pin memory in RAM
  dataloader:
    batch_size: 8
    shuffle: false
    num_workers: 16  # the number of subprocess to load data
    prefetch: 32  # samples to be prefetched. e.g. 64 means 64*num_workers samples to be prefetched
    label_smoothing: true
    epsilon: 0.2

edgeconv_block:
  K: [32, 32, 32]
  xyz_or_feature: ['feature', 'feature', 'feature']  # select K neighbors according to xyz or current feature
  feature_or_diff: ['diff', 'diff', 'diff']  # use the features of K neighbors or use the difference between the given point and its K neighbors as cross attention input
  conv1_channel_in: [6, 128, 128]
  conv1_channel_out: [64, 64, 64]
  conv2_channel_in: [64, 64, 64]
  conv2_channel_out: [64, 64, 64]

point2neighbor_block:
  enable: true  # if false, edgeconv block will be used
  use_embedding: true
  embedding_channels_in: 3
  embedding_channels_out: 64
  point2neighbor:
    K: [32, 32, 32]  # 3 values in the list means point2neighbor_block includes 3 point2neighbor layers. The 'K' for each layer is 32, 32 and 32 respectively
    xyz_or_feature: ['feature', 'feature', 'feature']  # select K neighbors according to xyz or current feature
    feature_or_diff: ['diff', 'diff', 'diff']  # use the features of K neighbors or use the difference between the given point and its K neighbors as cross attention input
    qkv_channels: [64, 64, 64]
    ff_conv1_channels_in: [64, 64, 64]
    ff_conv1_channels_out: [128, 128, 128]
    ff_conv2_channels_in: [128, 128, 128]
    ff_conv2_channels_out: [64, 64, 64]

conv_block:
  channels_in: [192]
  channels_out: [1024]

point2point_block:
  enable: false  # if false, conv block will be used
  use_embedding: true
  embedding_channels_in: 192
  embedding_channels_out: 1024
  point2point:
    qkv_channels: [1024]
    ff_conv1_channels_in: [1024]
    ff_conv1_channels_out: [512]
    ff_conv2_channels_in: [512]
    ff_conv2_channels_out: [1024]

point2neighbor_multi_scale:
  enable: true

point2patch:
  enable: true